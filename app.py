import os
import json
import time
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI
from pytrends.request import TrendReq
import matplotlib.pyplot as plt
import numpy as np

# =============================
# ç’°å¢ƒå¤‰æ•°ã®ãƒ­ãƒ¼ãƒ‰
# =============================
load_dotenv()
OPENAI_API_KEY = os.getenv("TNSYSTEM1")
if not OPENAI_API_KEY:
    st.error("âŒ .envã«OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

# =============================
# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š
# =============================
client = OpenAI(api_key=OPENAI_API_KEY)

# =============================
# Streamlit UI
# =============================
st.set_page_config(page_title="å¸‚å ´èª¿æŸ»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ", layout="wide")
st.title("ğŸ“Š å¸‚å ´èª¿æŸ» Ã— AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")

# =============================
# ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
# =============================
LEARNING_FILE = "learning_data.json"

# =============================
# åˆæœŸåŒ–
# =============================
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if not os.path.exists(LEARNING_FILE):
    with open(LEARNING_FILE, "w", encoding="utf-8") as f:
        json.dump([], f, ensure_ascii=False, indent=2)

# =============================
# ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—é–¢æ•°
# =============================
def fetch_trends(keyword, retries=5):
    pytrends = TrendReq(hl="ja-JP", tz=540)
    for i in range(retries):
        try:
            pytrends.build_payload([keyword], timeframe="today 3-m", geo="JP")
            data = pytrends.interest_over_time()
            if not data.empty:
                return data
        except Exception as e:
            if "429" in str(e):
                wait = 60
                st.warning(f"âš ï¸ TooManyRequestsError: {keyword}, {i+1}/{retries} ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™ {wait}ç§’å¾…æ©Ÿ...")
                time.sleep(wait)
            else:
                st.error(f"âŒ {keyword} ã®ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                break
    st.warning(f"âš ï¸ æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸ: {keyword}")
    return None

# =============================
# AIå¿œç­”é–¢æ•°
# =============================
def get_ai_response(user_input):
    # éå»ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    with open(LEARNING_FILE, "r", encoding="utf-8") as f:
        recent_learning = json.load(f)[-5:]

    conversation_context = st.session_state.chat_history + recent_learning

    prompt_messages = [{"role": "system", "content": "ã‚ãªãŸã¯å¸‚å ´èª¿æŸ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"}]

    # ç©ºãƒ‡ãƒ¼ã‚¿ã‚„Noneã‚’é™¤å¤–
    for m in conversation_context:
        role = m.get("role", "user")
        content = m.get("content", "")
        if isinstance(content, str) and content.strip():
            prompt_messages.append({"role": role, "content": content})

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’è¿½åŠ 
    if isinstance(user_input, str) and user_input.strip():
        prompt_messages.append({"role": "user", "content": user_input})
    else:
        return "(å…¥åŠ›ãŒç©ºã§ã™)"

    # OpenAI APIå‘¼ã³å‡ºã—
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            max_tokens=800,
            messages=prompt_messages
        )
        bot_output = response.choices[0].message.content or "(å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“)"
        return bot_output
    except Exception as e:
        return f"âš ï¸ ã‚¨ãƒ©ãƒ¼: {e}"

# =============================
# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¿å­˜
# =============================
def save_learning(user, bot):
    with open(LEARNING_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)
    data.append({"role": "user", "content": user})
    data.append({"role": "assistant", "content": bot})
    with open(LEARNING_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# =============================
# Streamlit ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
# =============================
st.sidebar.header("è¨­å®š")
keyword = st.sidebar.text_input("èª¿æŸ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", "ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹")
analyze_btn = st.sidebar.button("å¸‚å ´èª¿æŸ»ã‚’å®Ÿè¡Œ")

if analyze_btn:
    st.session_state.chat_history.append({"role": "user", "content": f"ã€Œ{keyword}ã€ã®å¸‚å ´å‹•å‘ã‚’èª¿ã¹ã¦"} )
    trends = fetch_trends(keyword)
    if trends is not None:
        st.line_chart(trends[keyword])
        ai_summary = get_ai_response(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€{keyword}ã€ã®Googleãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’è§£æã—ã€ãƒˆãƒ¬ãƒ³ãƒ‰å¤‰åŒ–ã®è¦å› ã‚’èª¬æ˜ã—ã¦ã€‚")
        st.session_state.chat_history.append({"role": "assistant", "content": ai_summary})
        save_learning(f"{keyword}ã®å¸‚å ´å‹•å‘åˆ†æ", ai_summary)
        st.markdown("### ğŸ¤– AIè§£æçµæœ")
        st.write(ai_summary)
    else:
        st.warning("ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

# =============================
# ãƒãƒ£ãƒƒãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
# =============================
st.markdown("---")
st.subheader("ğŸ’¬ æˆ¦ç•¥ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³")

user_input = st.text_input("ã‚ãªãŸã®è³ªå•ã‚„ææ¡ˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", key="chat_input")
if st.button("é€ä¿¡"):
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    response = get_ai_response(user_input)
    st.session_state.chat_history.append({"role": "assistant", "content": response})
    save_learning(user_input, response)
    st.markdown("**AI:** " + response)

# å±¥æ­´è¡¨ç¤º
st.markdown("### ğŸ“š ä¼šè©±å±¥æ­´")
for msg in st.session_state.chat_history[-10:]:
    role = "ğŸ§‘ ã‚ãªãŸ" if msg["role"] == "user" else "ğŸ¤– AI"
    st.write(f"**{role}:** {msg['content']}")
